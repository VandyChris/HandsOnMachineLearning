{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mnist data from datasets/mnist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('datasets/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the minist.train.next_batch function to observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = mnist.train.next_batch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction phase of DNN:\n",
    "1. Input layer\n",
    "2. Hidden layer 1 of 300 neurons, using ReLU activation function\n",
    "3. Hidden layer 2 of 100 neurons, using ReLU activation function\n",
    "4. Output layer\n",
    "\n",
    "This DNN applies gradient descent to minimize the entropy loss function.\n",
    "This DNN has an \"accuracy\" node to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_input), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('DNN'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name='hidden1')\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name='hidden2')\n",
    "    logits  = tf.layers.dense(hidden2, n_output, activation=None, name='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits), name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('training'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    training_op = optimizer.minimize(loss, name='training_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')\n",
    "    accuracy_summary = tf.summary.scalar('Accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase of DNN:\n",
    "1. Run 50 epoches at a batch size 100\n",
    "2. Print training and validation accuracy after each epoch, also save them to log file\n",
    "3. Save the final model at tmp/mnist_dnn_final.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "file_writer_training = tf.summary.FileWriter('logs/mnist_dnn/train', graph=tf.get_default_graph())\n",
    "file_writer_val     = tf.summary.FileWriter('logs/mnist_dnn/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "batch_size = 100\n",
    "n_data = mnist.train.num_examples\n",
    "n_step = int(np.ceil(n_data/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training accuray: 0.5484, validation accuracy: 0.5588\n",
      "Epoch: 1, training accuray: 0.6894, validation accuracy: 0.6938\n",
      "Epoch: 2, training accuray: 0.7623, validation accuracy: 0.7632\n",
      "Epoch: 3, training accuray: 0.8025, validation accuracy: 0.8056\n",
      "Epoch: 4, training accuray: 0.8229, validation accuracy: 0.8292\n",
      "Epoch: 5, training accuray: 0.8367, validation accuracy: 0.8438\n",
      "Epoch: 6, training accuray: 0.8473, validation accuracy: 0.8574\n",
      "Epoch: 7, training accuray: 0.8558, validation accuracy: 0.8628\n",
      "Epoch: 8, training accuray: 0.8627, validation accuracy: 0.8686\n",
      "Epoch: 9, training accuray: 0.8690, validation accuracy: 0.8760\n",
      "Epoch: 10, training accuray: 0.8735, validation accuracy: 0.8800\n",
      "Epoch: 11, training accuray: 0.8774, validation accuracy: 0.8846\n",
      "Epoch: 12, training accuray: 0.8807, validation accuracy: 0.8878\n",
      "Epoch: 13, training accuray: 0.8836, validation accuracy: 0.8908\n",
      "Epoch: 14, training accuray: 0.8865, validation accuracy: 0.8928\n",
      "Epoch: 15, training accuray: 0.8889, validation accuracy: 0.8942\n",
      "Epoch: 16, training accuray: 0.8908, validation accuracy: 0.8974\n",
      "Epoch: 17, training accuray: 0.8931, validation accuracy: 0.8994\n",
      "Epoch: 18, training accuray: 0.8948, validation accuracy: 0.9026\n",
      "Epoch: 19, training accuray: 0.8963, validation accuracy: 0.9030\n",
      "Epoch: 20, training accuray: 0.8983, validation accuracy: 0.9048\n",
      "Epoch: 21, training accuray: 0.9001, validation accuracy: 0.9068\n",
      "Epoch: 22, training accuray: 0.9020, validation accuracy: 0.9082\n",
      "Epoch: 23, training accuray: 0.9035, validation accuracy: 0.9092\n",
      "Epoch: 24, training accuray: 0.9044, validation accuracy: 0.9110\n",
      "Epoch: 25, training accuray: 0.9055, validation accuracy: 0.9110\n",
      "Epoch: 26, training accuray: 0.9067, validation accuracy: 0.9130\n",
      "Epoch: 27, training accuray: 0.9076, validation accuracy: 0.9148\n",
      "Epoch: 28, training accuray: 0.9089, validation accuracy: 0.9162\n",
      "Epoch: 29, training accuray: 0.9100, validation accuracy: 0.9162\n",
      "Epoch: 30, training accuray: 0.9109, validation accuracy: 0.9176\n",
      "Epoch: 31, training accuray: 0.9117, validation accuracy: 0.9192\n",
      "Epoch: 32, training accuray: 0.9126, validation accuracy: 0.9190\n",
      "Epoch: 33, training accuray: 0.9132, validation accuracy: 0.9202\n",
      "Epoch: 34, training accuray: 0.9141, validation accuracy: 0.9212\n",
      "Epoch: 35, training accuray: 0.9147, validation accuracy: 0.9222\n",
      "Epoch: 36, training accuray: 0.9155, validation accuracy: 0.9222\n",
      "Epoch: 37, training accuray: 0.9161, validation accuracy: 0.9232\n",
      "Epoch: 38, training accuray: 0.9168, validation accuracy: 0.9244\n",
      "Epoch: 39, training accuray: 0.9175, validation accuracy: 0.9246\n",
      "Epoch: 40, training accuray: 0.9180, validation accuracy: 0.9258\n",
      "Epoch: 41, training accuray: 0.9186, validation accuracy: 0.9256\n",
      "Epoch: 42, training accuray: 0.9196, validation accuracy: 0.9270\n",
      "Epoch: 43, training accuray: 0.9204, validation accuracy: 0.9282\n",
      "Epoch: 44, training accuray: 0.9207, validation accuracy: 0.9286\n",
      "Epoch: 45, training accuray: 0.9213, validation accuracy: 0.9296\n",
      "Epoch: 46, training accuray: 0.9219, validation accuracy: 0.9298\n",
      "Epoch: 47, training accuray: 0.9228, validation accuracy: 0.9302\n",
      "Epoch: 48, training accuray: 0.9231, validation accuracy: 0.9310\n",
      "Epoch: 49, training accuray: 0.9236, validation accuracy: 0.9306\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for step in range(n_step):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        (train_accuracy_val, train_accuracy_sum) = \\\n",
    "            sess.run([accuracy, accuracy_summary], feed_dict={X: mnist.train.images, y: mnist.train.labels})\n",
    "        \n",
    "        (val_accuracy_val, val_accuracy_sum) = \\\n",
    "            sess.run([accuracy, accuracy_summary], feed_dict={X: mnist.validation.images, y: mnist.validation.labels})\n",
    "        \n",
    "        print(\"Epoch: {}, training accuray: {:.4f}, validation accuracy: {:.4f}\".format(epoch, train_accuracy_val, val_accuracy_val))\n",
    "        \n",
    "        global_step = n_step * epoch + step\n",
    "        file_writer_training.add_summary(train_accuracy_sum, global_step=global_step)\n",
    "        file_writer_val.add_summary(val_accuracy_sum, global_step=global_step)\n",
    "    saver.save(sess, 'tmp/mnist_dnn_final.ckpt')\n",
    "    file_writer_training.close()\n",
    "    file_writer_val.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the DNN and the learning curve in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
