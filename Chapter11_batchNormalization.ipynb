{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('datasets/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = mnist.validation.images\n",
    "y_val = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define nodes for predictor X and target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namscope \"dnn\", define a network of:\n",
    "1. dense layer1 of n_hidden1 neurons\n",
    "2. batch normalization layer of momentum = 0.9\n",
    "3. ELU activation function\n",
    "4. dense layer2 of n_hidden2 neurons\n",
    "5. batch normalization layer of momentum = 0.9\n",
    "6. ELU activation function\n",
    "7. dense layer of n_outputs neurons\n",
    "8. batch normalization layer of momnetus = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=None, name='hidden1')\n",
    "    bn1 = tf.layers.batch_normalization(hidden1, momentum=0.9)\n",
    "    elu1 = tf.nn.elu(bn1)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(elu1, n_hidden2, activation=None, name='hidden2')\n",
    "    bn2 = tf.layers.batch_normalization(hidden2, momentum=0.9)\n",
    "    elu2 = tf.nn.elu(bn2)\n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(elu2, n_hidden2, activation=None)\n",
    "    logits = tf.layers.batch_normalization(logits_before_bn, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namescope \"loss\", define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namescope 'train', define the training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss, name='training_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namesope 'eval', define the node of accuracy and the summary node to log accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, y, 1), tf.float32), name='accuracy')\n",
    "    accuracy_summary = tf.summary.scalar('Accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter('logs/mnist_bn', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase: \n",
    "1. run 40 epoches, and use mini-batch size of 50\n",
    "2. After each epoch, print out the validation accuracy\n",
    "3. Save the final model to tmp/mnist_BN.ckpt\n",
    "4. Save log to visualize the graph and test accuracy learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 50\n",
    "n_step = int(np.ceil(mnist.train.num_examples / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9588\n",
      "Validation accuracy: 0.9680\n",
      "Validation accuracy: 0.9740\n",
      "Validation accuracy: 0.9732\n",
      "Validation accuracy: 0.9778\n",
      "Validation accuracy: 0.9800\n",
      "Validation accuracy: 0.9798\n",
      "Validation accuracy: 0.9778\n",
      "Validation accuracy: 0.9790\n",
      "Validation accuracy: 0.9762\n",
      "Validation accuracy: 0.9808\n",
      "Validation accuracy: 0.9824\n",
      "Validation accuracy: 0.9746\n",
      "Validation accuracy: 0.9824\n",
      "Validation accuracy: 0.9796\n",
      "Validation accuracy: 0.9774\n",
      "Validation accuracy: 0.9784\n",
      "Validation accuracy: 0.9818\n",
      "Validation accuracy: 0.9802\n",
      "Validation accuracy: 0.9808\n",
      "Validation accuracy: 0.9816\n",
      "Validation accuracy: 0.9818\n",
      "Validation accuracy: 0.9788\n",
      "Validation accuracy: 0.9818\n",
      "Validation accuracy: 0.9800\n",
      "Validation accuracy: 0.9820\n",
      "Validation accuracy: 0.9818\n",
      "Validation accuracy: 0.9828\n",
      "Validation accuracy: 0.9796\n",
      "Validation accuracy: 0.9814\n",
      "Validation accuracy: 0.9840\n",
      "Validation accuracy: 0.9808\n",
      "Validation accuracy: 0.9824\n",
      "Validation accuracy: 0.9820\n",
      "Validation accuracy: 0.9840\n",
      "Validation accuracy: 0.9808\n",
      "Validation accuracy: 0.9842\n",
      "Validation accuracy: 0.9826\n",
      "Validation accuracy: 0.9822\n",
      "Validation accuracy: 0.9820\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for step in range(n_step):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        [accuracy_val, sum_val] = sess.run([accuracy, accuracy_summary], feed_dict={X: X_val, y: y_val})\n",
    "        print('Validation accuracy: {:.4f}'.format(accuracy_val))\n",
    "        writer.add_summary(sum_val, global_step=batch_size * epoch + step)\n",
    "    saver.save(sess, 'tmp/mnist_BN.ckpt')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the graph and the validation accuracy learning curve in TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
