{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Chapter11_2, we load the graph and the parameter values. Another case is that we define the network and just load the parameters from the pre-trained model. Of course the reused parts should have the same definition in the new and old networks.\n",
    "\n",
    "In this example, we defined our own DNN network of five hidden layers, then load the weights up to the second hidden layer from tmp/mnist_dnn_final.ckpt. Then train the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tensorflow and reset the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mnist data and get X_train, y_train, X_val, and y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/minst/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/minst/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/minst/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/minst/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('datasets/minst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run next cell to define our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 100  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # new\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restor the parameters up to hidden layer 2 by 'tmp/mnist_dnn_final.ckpt', and run the model for another 20 epoches. Print out the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden[12]\")\n",
    "reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
    "restore_saver = tf.train.Saver(reuse_vars_dict)\n",
    "# or you can directly use\n",
    "# restore_saver = tf.train.Saver(reuse_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "batch_size = 50\n",
    "n_step = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/mnist_dnn_final.ckpt\n",
      "Epoch: 0, validation accuracy: 0.8156\n",
      "Epoch: 1, validation accuracy: 0.8696\n",
      "Epoch: 2, validation accuracy: 0.8914\n",
      "Epoch: 3, validation accuracy: 0.9034\n",
      "Epoch: 4, validation accuracy: 0.9096\n",
      "Epoch: 5, validation accuracy: 0.9142\n",
      "Epoch: 6, validation accuracy: 0.9182\n",
      "Epoch: 7, validation accuracy: 0.9206\n",
      "Epoch: 8, validation accuracy: 0.9236\n",
      "Epoch: 9, validation accuracy: 0.9252\n",
      "Epoch: 10, validation accuracy: 0.9272\n",
      "Epoch: 11, validation accuracy: 0.9296\n",
      "Epoch: 12, validation accuracy: 0.9308\n",
      "Epoch: 13, validation accuracy: 0.9324\n",
      "Epoch: 14, validation accuracy: 0.9328\n",
      "Epoch: 15, validation accuracy: 0.9362\n",
      "Epoch: 16, validation accuracy: 0.9368\n",
      "Epoch: 17, validation accuracy: 0.9364\n",
      "Epoch: 18, validation accuracy: 0.9388\n",
      "Epoch: 19, validation accuracy: 0.9396\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    restore_saver.restore(sess, 'tmp/mnist_dnn_final.ckpt')\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for step in range(n_step):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict = {X:X_batch, y:y_batch})\n",
    "        accuracy_val = sess.run(accuracy, feed_dict={X: mnist.validation.images, y: mnist.validation.labels})\n",
    "        print(\"Epoch: {}, validation accuracy: {:.4f}\".format(epoch, accuracy_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
