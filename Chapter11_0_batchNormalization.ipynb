{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('datasets/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = mnist.validation.images\n",
    "y_val = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define nodes for predictor X and target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "training = tf.placeholder_with_default(False, (), name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namscope \"dnn\", define a network of:\n",
    "1. dense layer1 of n_hidden1 neurons\n",
    "2. batch normalization layer of momentum = 0.9\n",
    "3. ELU activation function\n",
    "4. dense layer2 of n_hidden2 neurons\n",
    "5. batch normalization layer of momentum = 0.9\n",
    "6. ELU activation function\n",
    "7. dense layer of n_outputs neurons\n",
    "8. batch normalization layer of momnetus = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=None, name='hidden1')\n",
    "    bn1 = tf.layers.batch_normalization(hidden1, momentum=0.9,\n",
    "                                       training=training, name='batch_norm1')\n",
    "    elu1 = tf.nn.elu(bn1, name='ELU1')\n",
    "    \n",
    "    hidden2 = tf.layers.dense(elu1, n_hidden2, activation=None, name='hidden2')\n",
    "    bn2 = tf.layers.batch_normalization(hidden2, momentum=0.9,\n",
    "                                       training=training, name='batch_norm2')\n",
    "    elu2 = tf.nn.elu(bn2, name='ELU2')\n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(elu2, n_hidden2, activation=None)\n",
    "    logits = tf.layers.batch_normalization(logits_before_bn, momentum=0.9,\n",
    "                                          training=training, name='outputs_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namescope \"loss\", define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namescope 'train', define the training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss, name='training_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the namesope 'eval', define the node of accuracy and the summary node to log accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, y, 1), tf.float32), name='accuracy')\n",
    "    accuracy_summary = tf.summary.scalar('Accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter('logs/mnist_bn', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase: \n",
    "1. run 40 epoches, and use mini-batch size of 50\n",
    "2. After each epoch, print out the validation accuracy\n",
    "3. Save the final model to tmp/mnist_BN.ckpt\n",
    "4. Save log to visualize the graph and test accuracy learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 50\n",
    "n_step = int(np.ceil(mnist.train.num_examples / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Validation accuracy: 0.9646\n",
      "Epoch: 1, Validation accuracy: 0.9704\n",
      "Epoch: 2, Validation accuracy: 0.9748\n",
      "Epoch: 3, Validation accuracy: 0.9766\n",
      "Epoch: 4, Validation accuracy: 0.9798\n",
      "Epoch: 5, Validation accuracy: 0.9786\n",
      "Epoch: 6, Validation accuracy: 0.9800\n",
      "Epoch: 7, Validation accuracy: 0.9800\n",
      "Epoch: 8, Validation accuracy: 0.9780\n",
      "Epoch: 9, Validation accuracy: 0.9816\n",
      "Epoch: 10, Validation accuracy: 0.9820\n",
      "Epoch: 11, Validation accuracy: 0.9824\n",
      "Epoch: 12, Validation accuracy: 0.9796\n",
      "Epoch: 13, Validation accuracy: 0.9830\n",
      "Epoch: 14, Validation accuracy: 0.9818\n",
      "Epoch: 15, Validation accuracy: 0.9818\n",
      "Epoch: 16, Validation accuracy: 0.9836\n",
      "Epoch: 17, Validation accuracy: 0.9848\n",
      "Epoch: 18, Validation accuracy: 0.9840\n",
      "Epoch: 19, Validation accuracy: 0.9836\n",
      "Epoch: 20, Validation accuracy: 0.9836\n",
      "Epoch: 21, Validation accuracy: 0.9830\n",
      "Epoch: 22, Validation accuracy: 0.9814\n",
      "Epoch: 23, Validation accuracy: 0.9822\n",
      "Epoch: 24, Validation accuracy: 0.9814\n",
      "Epoch: 25, Validation accuracy: 0.9808\n",
      "Epoch: 26, Validation accuracy: 0.9836\n",
      "Epoch: 27, Validation accuracy: 0.9838\n",
      "Epoch: 28, Validation accuracy: 0.9836\n",
      "Epoch: 29, Validation accuracy: 0.9836\n",
      "Epoch: 30, Validation accuracy: 0.9834\n",
      "Epoch: 31, Validation accuracy: 0.9816\n",
      "Epoch: 32, Validation accuracy: 0.9818\n",
      "Epoch: 33, Validation accuracy: 0.9842\n",
      "Epoch: 34, Validation accuracy: 0.9822\n",
      "Epoch: 35, Validation accuracy: 0.9830\n",
      "Epoch: 36, Validation accuracy: 0.9824\n",
      "Epoch: 37, Validation accuracy: 0.9842\n",
      "Epoch: 38, Validation accuracy: 0.9834\n",
      "Epoch: 39, Validation accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for step in range(n_step):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops], feed_dict={training:True, X: X_batch, y: y_batch})\n",
    "        [accuracy_val, sum_val] = sess.run([accuracy, accuracy_summary], feed_dict={X: X_val, y: y_val})\n",
    "        print('Epoch: {}, Validation accuracy: {:.4f}'.format(epoch, accuracy_val))\n",
    "        writer.add_summary(sum_val, global_step=batch_size * epoch + step)\n",
    "    saver.save(sess, 'tmp/mnist_BN.ckpt')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the graph and the validation accuracy learning curve in TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
